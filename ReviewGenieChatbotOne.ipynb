{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Meet Review Genie, a conversational chatbot for your e-commerce platform's reviews."
      ],
      "metadata": {
        "id": "CkaZ15bkt6SM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9ZmExzDRva"
      },
      "source": [
        "### Understanding the Limitation of the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xRit5A9KCx20"
      },
      "outputs": [],
      "source": [
        "# Importing the OpenAI library to interact with OpenAI's API services.\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKBjz45zDj6r",
        "outputId": "d0fcd139-6a9b-4b1b-9216-5c871f1b48c2",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os  # Importing the os module to interact with environment variables\n",
        "import getpass  # Importing getpass to securely input sensitive information\n",
        "\n",
        "# Prompting the user to securely enter their OpenAI API key without displaying it on the screen\n",
        "OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vtvWPnanDkAj"
      },
      "outputs": [],
      "source": [
        "# Defining the prompt to query the LLM\n",
        "prompt = ''' What was uber's revenue in 2022? '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jBFCA_A_DWBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37463ee-c39d-4ad6-dbac-889e47dfd695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I cannot provide real-time information as I am an AI and do not have access to the internet. It is recommended to check the company's official website or financial reports for the most up-to-date information on Uber's revenue in 2022.\n"
          ]
        }
      ],
      "source": [
        "# Sending a request to the OpenAI API to generate a chat response\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "openai_response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',  # Specifying the model to use;\n",
        "    # Note: An older model chosen for testing purposes because the cutoff is 2021 whereas prompt is querying details about 2022\n",
        "    messages=[{'role': 'user', 'content': prompt}]  # Creating a structured message for the AI model\n",
        ")\n",
        "print(openai_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nSAk_2EGD1CC"
      },
      "outputs": [],
      "source": [
        "## Let's create the above context for the prompt\n",
        "# Defining a context string with revenue details retrieved from an external source.\n",
        "retrieved_context = '''Revenue was $37.3 billion, up 17% year-over-year. Mobility revenue increased $5.8 billion primarily attributable to an increase in\n",
        "               Mobility Gross Bookings of 31% year-over-year.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Irw2unBKFb0M"
      },
      "outputs": [],
      "source": [
        "## Let's modify our prompt now\n",
        "# Creating a prompt by embedding the retrieved context into a question for the AI model.\n",
        "\n",
        "prompt = f\"What was Uber's revenue in 2022? Check in {retrieved_context}\"\n",
        "\n",
        "# Note: The AI is being asked to analyze the given context and provide Uber's revenue for 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R70ZN0eKFoo7"
      },
      "outputs": [],
      "source": [
        "## Let's ask the LLM again\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': prompt}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "09ddo9F1Fs-w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96222de1-0603-4b21-9f00-a3c815ac3b8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As of now, it is not possible to accurately provide the revenue for Uber in 2022 as the year has not yet concluded. It is advisable to check the company's financial reports at the end of the year for the most up-to-date information on their revenue for 2022.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Accessing the generated response from the AI model.\n",
        "openai_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ekric37zU6aV",
        "outputId": "92a7cc5a-35d0-4982-c213-8636aab41f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.3)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchainhub) (2025.1.31)\n",
            "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.21 types-requests-2.32.0.20250328\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.50)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.70.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.3.23)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.13.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.11.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.12 tiktoken-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.24.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.24.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.24.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# Installing the LangChain Hub package to access and manage pre-built AI chains, prompts, and agents.\n",
        "!pip install langchainhub\n",
        "\n",
        "# Installing the LangChain OpenAI integration to use OpenAI models within LangChain workflows.\n",
        "!pip install langchain-openai\n",
        "\n",
        "# Installing the core LangChain library for building LLM-based applications, including chaining, memory, and retrieval capabilities.\n",
        "!pip install langchain\n",
        "\n",
        "# Installing the community version of LangChain, which includes integrations and tools contributed by the community.\n",
        "!pip install langchain-community\n",
        "\n",
        "# Installing FAISS (Facebook AI Similarity Search) for efficient similarity-based search on text embeddings.\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# Installing Gradio, a framework to create web-based UIs for AI models and applications easily.\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KqC1rIL7IyXt"
      },
      "outputs": [],
      "source": [
        "# Importing the KaggleHub library to interact with datasets and models available on Kaggle.\n",
        "import kagglehub\n",
        "\n",
        "# Importing the CSV module for reading and writing CSV files.\n",
        "import csv\n",
        "\n",
        "# Importing pandas for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy for numerical operations and handling arrays efficiently.\n",
        "import numpy as np\n",
        "\n",
        "# Importing os to interact with the operating system, such as environment variables and file paths.\n",
        "import os\n",
        "\n",
        "# Importing getpass to securely handle user input (e.g., API keys or passwords).\n",
        "import getpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Vphy17StbK"
      },
      "source": [
        "### STEP 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Mounting to the default Google Drive location in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQvqZVVWz-4Z",
        "outputId": "91fb21ea-358e-4de3-b5f0-4c63def425e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xx='/content/drive/MyDrive/IK-KickStart/ProjectUp/Gene/Project/'\n",
        "file_name='/content/drive/MyDrive/IK-Company/ProjectUp/Gene/Project/MyData/dataset/prod_small.csv'"
      ],
      "metadata": {
        "id": "VKVh3zGx2dTO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: unzip a file\n",
        "\n",
        "# !unzip \"/content/drive/MyDrive/IK-Company/ProjectUp/Gene/Project/archive.zip\" -d \"/content/drive/MyDrive/IK-Company/ProjectUp/Gene/Project/MyData\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAcnWAea0yS6",
        "outputId": "d89a71d9-9d34-4c5e-98ac-8cabb88b4477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/IK-KickStart/ProjectUp/Gene/Project/archive.zip\n",
            "  inflating: /content/drive/MyDrive/IK-KickStart/ProjectUp/Gene/Project/MyData/dataset/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0XiPvpp1FxKb"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "df = pd.read_csv(file_name,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MznuqvAmRx_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "fb0a37fd-b8e3-4c4d-daa6-0fad54f419aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PRODUCT_ID                                              TITLE  \\\n",
              "0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n",
              "1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n",
              "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
              "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
              "4      283658  The United Empire Loyalists: A Chronicle of th...   \n",
              "\n",
              "                                       BULLET_POINTS  \\\n",
              "0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n",
              "1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n",
              "2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
              "3  [Made By 95%cotton and 5% Lycra which gives yo...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
              "0                                                NaN             1650   \n",
              "1                                                NaN             2755   \n",
              "2  Specifications: Color: Red, Material: Aluminiu...             7537   \n",
              "3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
              "4                                                NaN             6112   \n",
              "\n",
              "   PRODUCT_LENGTH  \n",
              "0     2125.980000  \n",
              "1      393.700000  \n",
              "2      748.031495  \n",
              "3      787.401574  \n",
              "4      598.424000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcc556a9-e31d-49db-8c98-518d3b628520\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1925202</td>\n",
              "      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n",
              "      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1650</td>\n",
              "      <td>2125.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2673191</td>\n",
              "      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n",
              "      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2755</td>\n",
              "      <td>393.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2765088</td>\n",
              "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
              "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
              "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
              "      <td>7537</td>\n",
              "      <td>748.031495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1594019</td>\n",
              "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
              "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
              "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
              "      <td>2996</td>\n",
              "      <td>787.401574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>283658</td>\n",
              "      <td>The United Empire Loyalists: A Chronicle of th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6112</td>\n",
              "      <td>598.424000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc556a9-e31d-49db-8c98-518d3b628520')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcc556a9-e31d-49db-8c98-518d3b628520 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcc556a9-e31d-49db-8c98-518d3b628520');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdc5219d-a5cc-4a35-94d1-32f69d66d17f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdc5219d-a5cc-4a35-94d1-32f69d66d17f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdc5219d-a5cc-4a35-94d1-32f69d66d17f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"PRODUCT_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 852274,\n        \"min\": 54125,\n        \"max\": 2998633,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          499846,\n          1033263,\n          2763742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TITLE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Troop Leader Planner: A Complete Must-Have Troop Organizer, Dated Aug 2019 - Aug 2020\",\n          \"Fruit of the Loom Men&#39;s Fleece Full Zip Hoodie\",\n          \"Attiris Women's Satin Semi-Stitched Lehenga Choli (Green, Satin)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BULLET_POINTS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"[LUXURIOUS & APPEALING: Beautiful custom-made curtains to decorate any home or office | Includes inbuilt tieback to hold the curtain | Completely finished and ready to hang on walls & windows,MATERIAL: Luxurious & versatile fabric with a natural finish | High colour fastness | State-of-the-art digital printing ensures colour consistency and prevents any fading | Eyelets; Cotton Canvas; Width 4.5feet (54inch) | Multicolour | PACKAGE: 2 Room Curtains Eyelets | SIZE: Height 5 feet (60 inch); SET OF 2 PCS,BLACKOUT CURTAIN: 100% opaque & heavy premium cotton canvas fabric | Tight knitted, long life & durable fabric | Printing only on front side with a plain colour back side,MADE TO PERFECTION: Large eyelets at the top to put hanging hooks | Perfectly tailored seams for durability | Refined stitching with a matching thread color,QUALITY ASSURED: Gentle wash with similar colors in cold water | Avoid direct sunlight to prevent fading | Dispatched after MULTIPLE QUALITY CHECKS]\",\n          \"[HIGH QUALITY PVC MATERIAL: The kitchen aluminum foil stickers are made from plastic and aluminum foil, which is much stronger against high temperature than normal PVC sheet. The Anti-bacterial, Anti-mold, and Eco-friendly PVC materials is safe enough to use in Kitchen.,EASY TO USE AND CLEAN: Self-adhesive kitchen wallpaper is easy to stick on the dry, clean and smooth surface. Anti-oil, anti-dust and anti-water, anti-moisture PVC material allows you to wipe stains easily.,EASY CUT AND TRIM: back cut-to-fit grid lines design of the self-adhesive kitchen oil proof sticker is convenient for you to cut and trim any size you want. This silver rhombus texture add more fashion to your kitchen decor.,MULTI-USAGE: The kitchen backsplash wallpaper is great for home decorations to be used in kitchen cabinets ,countertop ,shelves, walls ,Pantry areas ,Dishwashers, Dishwasher Panels, Oven Hood, Refrigerators ,appliance etc, instant peel and apply to flat surfaces.,Anti-oil, anti-dust and anti-water: made from plastic and aluminum foil, much stronger against fire than normal PVC sheet. Resistant to heat and moisture, Easy wipe to remove the stains!]\",\n          \"[COMPLETELY BREATHABLE and 100% ECO-FRIENDLY-The breathable storage bags made with nonwon fabric that allows air to circulate inside, ultimately keeping stored items fresh for longer.Can folding in a small size, save more space if not in use.,DOUBLE STRONG ZIPPERS-The comforts storage bag has double smooth zippers so can open from the end or middle which make the storage bags easy to open and close.The zippers works well even with the bag full.Our zippers are much stronger and bigger than others.We can promise that ours can be used more than 1000 times (not like most cheap underbed bags where zipper break after only few uses).,EASY TO CARRY-Side double handles and front two handles make them easy to carry or grab and pull out from under the bed.,INSTANTLY KNOW WHAT'S INSIDE-Through the transparent top you can find the clothes, blankets, comforts conveniently and quickly without opening the blankets storage bags.,MULTIPURPOSE STORAGE OPTIONS-This underbed storage bag fits perfectly under your bed stacked on each other ,They are large enough that I fit 4 quilts (1 twin, 2 full/queen and a king) plus some pillowcases in just one of them..Also Works great for storing blankets and off season clothes.Dimensions: 39.37\\\"x19.68\\\"x5.90\\\" inches]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DESCRIPTION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 48,\n        \"samples\": [\n          \"<b>Under the Bed Storage Containers,Underbed Storage Bins Organizer for Blanket Clothes, Tidy Up Your Closet and Shelf,with Clear Window,2 Sturdy Zippers,4 Strong Handles Set of 2 Coffee with Lantern Printing</b><br> <b>COLOR:white with lantern printing</b><br> <b>SIZE:39.37\\\"x19.68\\\"x5.90\\\"</b><br> <b>Comforter breathable storage bag, Double strong zippers easy to carry or grab fits great under your bed</b><br> -Closet Soft Storage Bag With Clear Window Zippers and Handles ,classify Clothing,Comforters,Holiday Ornaments,Quilts, Blankets.<br> -Whether you want to tidy up your closets or create extra storage space under the bed, this versatile underbed organizer has got you covered in perfect style.<br> -Not only for under the bed, also for guestroom, down the attic stairs, your apartment with limited space to spare. They fold down to flat square when not in use.<br> -The jumbo blanket storage bag?is sturdy and durable.\",\n          \"Body by wacoal seamless underwire is sleek and modern\",\n          \"<p><b>Feature:</b></p><p>1. 480X320 HD resolution, only a few IO can light up the display<br>2. With memory card slot to facilitate the expansion of the experiment, provide a wealth of sample programs<br>3. Multifunctional use, can be used for other display functions through the signal transmission line<br>4. Small size, easy to carry and store, convenient to use and with good performance<br>5. Strict quality control and quality assurance, high safety factor, can be used with peace of mind</p><p><br></p><p><b>Spec:</b></p>Item Type: LCD Screen ModuleSize: Approx. 3.5 (inch)<br>Type: TFT<br>Driver Chip: ILI9488<br>Resolution: 480 x 320 (Pixel)<br>Module Interface: 4-wire SPI interface<br>Effective Display Area: (AA area) 48.96 x 73.44mm / 1.9 x 2.9in&nbsp;<br>Module PCB Floor Size: Approx.56.34 x 98mm / 2.2 x 3.9in&nbsp;<br>VCC Power Supply Voltage: 3.3V~5V<br>Logic I/O Voltage: 3.3V (TTL) <p><br></p><p><b>Package List:</b></p>1 x LCD Screen Module\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRODUCT_TYPE_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3640,\n        \"min\": 0,\n        \"max\": 13101,\n        \"num_unique_values\": 87,\n        \"samples\": [\n          98,\n          1650,\n          2879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRODUCT_LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1370.245424206136,\n        \"min\": 10.0,\n        \"max\": 8858.25,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          640.0,\n          2125.98,\n          800.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Viewing the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3RpjmUS21M"
      },
      "source": [
        "**Constructing the text data**\n",
        "\n",
        "It's useful to use both `Title` and `Description`. To help downstream models understand which content is title and which content is description, we will add a prefix explaining which section is title and which is description. So each row should look like\n",
        "\n",
        "```\n",
        "Title\n",
        "{Title}\n",
        "Description\n",
        "{Description}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MduzbFnMSdNo"
      },
      "outputs": [],
      "source": [
        "## Let's construct the text data\n",
        "# Initializing empty lists to store product descriptions and their lengths\n",
        "import math\n",
        "product_description =[]\n",
        "product_description_len =[]\n",
        "\n",
        "# Iterating through each row in the dataframe df2\n",
        "for row in df.iterrows():\n",
        "    product = \"\"  # Initialize an empty string to accumulate product details\n",
        "\n",
        "    # Extracting the product title from the current row\n",
        "    title = row[1]['TITLE']\n",
        "\n",
        "    # Checking if the title is valid (not NaN or missing)\n",
        "    if type(title) != float or not math.isnan(title):\n",
        "        product += \"Title\\n\" + title + \"\\n\"  # Append the title to the product description\n",
        "\n",
        "    # Extracting the product description from the current row\n",
        "    description = row[1]['DESCRIPTION']\n",
        "\n",
        "    # Checking if the description is valid (not NaN or missing)\n",
        "    if type(description) != float or not math.isnan(description):\n",
        "        product += \"Description\\n\" + description + \"\\n\"  # Append the description to the product details\n",
        "\n",
        "    # Check if either title or description was added\n",
        "    added_content = title or description\n",
        "    if added_content:\n",
        "        product = product.strip()  # Remove any leading/trailing whitespace\n",
        "        product_description.append(product)  # Add the formatted product details to the list\n",
        "        product_description_len.append(len(product))  # Store the length of the product description\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Rd2Tpb2dTeQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786f0340-adbd-4b86-95d4-23fed24a8c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements 100\n"
          ]
        }
      ],
      "source": [
        "# Checking the length of the data\n",
        "print(f\"Number of elements {len(product_description)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n7JLY31mTx0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "6aaac950-9bd5-47f8-ef00-69152bacfdd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Title\\nHINS Metal Bucket Shape Plant Pot for Indoor & Outdoor Gardening (Red, Medium) Plant Stands for Indoor Balcony I Plant Bench I Plant Stands I Pot Stand Single I Potted Plant Stand I Big Pots I Metal\\nDescription\\nHINS Brings you the most Elegant Looking Pot with Stand for durable and long life Pot Stands for your lovely garden space, office and home. HINS is one of the best choice when it comes to indoor plants. It makes a good choice for housewarming gift. This beautiful product will take center stage with its sprawling design when planted with a plant. The metal stands are painted with powder-coated paint that will protect the galvanized iron from rusting. It will also prevent the color from fading. Each planter pot is removable for easy mobility, allowing you to switch out plants depending on your mood Note- Monitors are not calibrated same, item color displayed in photos may be showing slightly different from the real object. Please take the real one as standard. Please allow 0~2cm errors due to manual measurement.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Check a sample product description data\n",
        "product_description[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kaPPz4ebT0P4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab8f93d-9b8a-4927-df7b-59b6c616dc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items 100\n",
            "Min Length of the description: 18\n",
            "Avg Length of the description: 385.9\n",
            "Median of the description: 120.0\n",
            "Max Length of the description: 1834\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of product descriptions processed\n",
        "print(\"Number of items\", len(product_description_len))\n",
        "\n",
        "# Print the minimum length of the product descriptions\n",
        "print(\"Min Length of the description:\",np.min(product_description_len))\n",
        "\n",
        "# Print the average (mean) length of the product descriptions\n",
        "print(\"Avg Length of the description:\",np.mean(product_description_len))\n",
        "\n",
        "print(\"Median of the description:\",np.median(product_description_len))\n",
        "\n",
        "# Print the maximum length of the product descriptions\n",
        "print(\"Max Length of the description:\",np.max(product_description_len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4y4JSH_Svat"
      },
      "source": [
        "### Interpretation:\n",
        "\n",
        "What does the above result signify about the data?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hwFdqweOT2xI"
      },
      "outputs": [],
      "source": [
        "# Importing RecursiveCharacterTextSplitter from LangChain for chunking large text into smaller, manageable pieces.\n",
        "# This helps in optimizing text for processing and retrieval.\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Importing OpenAIEmbeddings from LangChain to generate numerical vector representations (embeddings) of text.\n",
        "# These embeddings capture the semantic meaning of the text for efficient similarity searches.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importing FAISS (Facebook AI Similarity Search) from LangChain's community package.\n",
        "# FAISS is used for storing and retrieving embeddings efficiently by finding similar vectors.\n",
        "from langchain_community.vectorstores import FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2X3hxmTTUsr1"
      },
      "outputs": [],
      "source": [
        "# Setting the OpenAI API key as an environment variable.\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PD-uoBzLVtdw"
      },
      "outputs": [],
      "source": [
        "# Split the input text using Recursive Character Chunking\n",
        "# See this for more details https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        ")\n",
        "documents = text_splitter.create_documents(product_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ptE8XpNLWD--"
      },
      "outputs": [],
      "source": [
        "# Create an embedding model using LangChain.\n",
        "# One option is using https://python.langchain.com/docs/integrations/text_embedding/openai/\n",
        "# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sSlO9vblWGDt"
      },
      "outputs": [],
      "source": [
        "# Create a vector store using the created chunks and the embeddings model\n",
        "vector = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nElsMdbeW4l1"
      },
      "outputs": [],
      "source": [
        "# Importing ChatOpenAI from LangChain to interact with OpenAI's language models, such as GPT, for generating responses.\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Importing ChatPromptTemplate to create structured prompts for the chatbot, ensuring consistent interactions with the AI model.\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Importing OpenAIEmbeddings to convert text data into numerical vector representations for similarity search and retrieval.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importing ChatPromptTemplate again (duplicate import, should be removed to avoid redundancy).\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Importing create_stuff_documents_chain to combine and process retrieved documents for meaningful AI-generated responses.\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# Importing create_retrieval_chain to build a chain that retrieves relevant documents from a vector store and generates AI responses.\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "# Importing StrOutputParser from LangChain to parse the output\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explanation:\n",
        "- `ChatOpenAI` – Used to access OpenAI models for chatbot functionality.\n",
        "- `ChatPromptTemplate` – Helps structure queries to ensure better responses.\n",
        "- `OpenAIEmbeddings` – Converts text into vector form for similarity-based retrieval.\n",
        "- `create_stuff_documents_chain` – Combines retrieved documents meaningfully before passing to the LLM.\n",
        "- `create_retrieval_chain` – Automates the process of retrieving and utilizing relevant content for AI responses.\n",
        "- `StrOutputParser` - For processing the output of language models, ensuring that the output is returned as a plain string"
      ],
      "metadata": {
        "id": "xVChvJAijx-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6dJXzILCXStu"
      },
      "outputs": [],
      "source": [
        "# Initializing the ChatOpenAI model to interact with OpenAI's GPT model.\n",
        "llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model = 'gpt-4o-mini')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the output parser to process and format the model's response into a readable string format.\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Creating a prompt template that instructs the AI to act as a customer service agent.\n",
        "# The prompt takes two parameters:\n",
        "#   1. {context} - Relevant information retrieved from the document store.\n",
        "#   2. {input} - The user's question.\n",
        "# The model is instructed to base its answer solely on the provided context.\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Answer the following question based only on the provided context:\n",
        "\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "\n",
        "    Question: {input}\"\"\",\n",
        "    output_parser= output_parser                  # The output parser ensures that the response is returned in a structured string format.\n",
        ")\n",
        "\n",
        "# Creating a document processing chain using the LLM and the defined prompt template.\n",
        "# This chain takes a list of retrieved documents and passes them as context to the model for generating responses.\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Alternative chain creation method:\n",
        "# Using the \"|\" (pipe) operator to link the prompt with the language model (llm),\n",
        "# meaning the input first goes to the prompt and then to the model for response generation.\n",
        "# document_chain = prompt | llm\n"
      ],
      "metadata": {
        "id": "dPJ3yFeEk9EN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_parser)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFX5zVc5pQnx",
        "outputId": "1e65b616-1dff-4363-92dd-c12251f76af5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retriever from the vector store for fetching relevant documents\n",
        "# See https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/vectorstore/\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# Create a retrieval chain that first retrieves relevant documents and then processes them using the document chain\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n"
      ],
      "metadata": {
        "id": "VMiWghjrl5oB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wUqxhEW3XcJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e99b55-5a1c-4e0e-c194-5f69cff8a5cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what are some of the best shoes available?',\n",
              " 'context': [Document(id='a80618be-10a4-44cc-801f-a2d5345d18fd', metadata={}, page_content=\"Title\\nadidas Men's Predator 18+ FG Firm Ground Soccer Cleats\\nDescription\\nadidas Predator 18+ FG- Black 7.5\"),\n",
              "  Document(id='a4858158-0b84-4d63-8aa2-0c7d81d9b6ea', metadata={}, page_content=\"Title\\nKenneth Cole REACTION Men's Crespo Loafer B Shoe, Cognac, 10 M US\"),\n",
              "  Document(id='fdceed15-5a5d-4fd4-8e57-ebd3710f880e', metadata={}, page_content=\"Title\\nPUMA Cali Sport Clean Women's Sneakers White Leather (37540701)\"),\n",
              "  Document(id='815410f6-cece-405d-bedb-af16650f3bb1', metadata={}, page_content=\"The Remora Climbing Shoe is Mad Rock's do-it-all slipper for climbers who can't have separate shoes for boulders, sport routes, and gyms. With a moderately stiff, slightly downturned design, the Remora performs on any climb at steep to vertical\")],\n",
              " 'answer': \"Based on the provided context, some of the best shoes available include:\\n\\n1. adidas Men's Predator 18+ FG Firm Ground Soccer Cleats\\n2. Kenneth Cole REACTION Men's Crespo Loafer B Shoe\\n3. PUMA Cali Sport Clean Women's Sneakers\\n4. Mad Rock Remora Climbing Shoe\\n\\nThese shoes cater to different activities, including soccer, casual wear, and climbing.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Invoking the retrieval chain to process the user's query.\n",
        "# The query \"what are some of the best shoes available?\" is passed as input.\n",
        "# The retrieval chain first fetches relevant product descriptions from the vector store,\n",
        "# then processes them using the document chain to generate a meaningful AI response.\n",
        "retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QqNvod6GXfjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "11fb09ba-c784-4889-ee01-45086ad540d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided context, some of the best shoes available include:\\n\\n1. adidas Men's Predator 18+ FG Firm Ground Soccer Cleats\\n2. Kenneth Cole REACTION Men's Crespo Loafer B Shoe\\n3. PUMA Cali Sport Clean Women's Sneakers\\n4. Mad Rock Remora Climbing Shoe\\n\\nThese shoes cater to various needs such as soccer, casual wear, lifestyle, and climbing.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Fetching the final answer from the retrieval chain by invoking it with a user query.\n",
        "# The ['answer'] key extracts the final AI-generated answer from the response dictionary.\n",
        "retrieval_chain.invoke({\"input\": \"what are some of the best shoes available?\"})['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we got the answer! But, the formatting is not very good, right? Lets create a simple UI for our bot."
      ],
      "metadata": {
        "id": "2tMQ3SGUnoad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process the user query and return formatted product names\n",
        "def final_response(user_query):\n",
        "    # Invoking the retrieval chain with the user's query to fetch relevant product information\n",
        "    response = retrieval_chain.invoke({\"input\": user_query})['answer']\n",
        "\n",
        "    # Creating a prompt to instruct the AI to format the response properly\n",
        "    # The prompt asks the AI to extract only product names from the retrieved response\n",
        "    prompt = f\"Format the responses properly in {response}. Just return the product names, no other text\"\n",
        "\n",
        "    # Sending the formatted prompt to the GPT-4o-mini model for processing\n",
        "    openai_response = client.chat.completions.create(\n",
        "        model='gpt-4o-mini',  # Using GPT-4o-mini model for response generation\n",
        "        messages=[{'role': 'user', 'content': prompt}]  # Providing the prompt to the model\n",
        "    )\n",
        "\n",
        "    # Extracting and returning the AI-generated response containing only the product names\n",
        "    return openai_response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "PcAbbKmKoHZO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ttosPCA2bLYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e17aa40-f4f9-4702-c372-e490f8030e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. adidas Men's Predator 18+ FG Firm Ground Soccer Cleats  \n",
            "2. Kenneth Cole REACTION Men's Crespo Loafer B Shoe  \n",
            "3. PUMA Cali Sport Clean Women's Sneakers  \n",
            "4. Mad Rock Remora Climbing Shoe  \n"
          ]
        }
      ],
      "source": [
        "# Printing the final response\n",
        "print(final_response(\"what are some of the best shoes available?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jjS_RUh6ZstZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "7a2cdbd1-c3f8-4be2-f71e-522109b6ea10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://278aae15be4ad8f5c7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://278aae15be4ad8f5c7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Importing the Gradio library to create a simple web-based user interface\n",
        "import gradio as gr\n",
        "\n",
        "# Creating the Gradio interface for the product recommendation system\n",
        "app = gr.Interface(\n",
        "    fn= final_response,        # The function that processes user input and returns recommendations\n",
        "    inputs= \"text\",            # Input component: a text box for users to enter their query\n",
        "    outputs= \"text\" ,           # Output component: a text box to display the AI-generated response\n",
        "    title= \"Review Gene\"        ,     # The title of the web interface\n",
        "    description= \"Type your question to get recommendations\"          ,# A brief description displayed to users\n",
        "    theme=\"Ocean\",\n",
        "    allow_flagging=\"never\"    # Disabling the flagging feature to remove the \"Flag\" button\n",
        ")\n",
        "\n",
        "# Launching the Gradio app to start the interface and make it accessible via web browser\n",
        "app.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}